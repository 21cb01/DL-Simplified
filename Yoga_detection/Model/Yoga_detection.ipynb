{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Yoga Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp \n",
    "import numpy as np \n",
    "import cv2 \n",
    "\n",
    "import os  \n",
    "import numpy as np \n",
    "import cv2 \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Input, Dense \n",
    "from keras.models import Model\n",
    "\n",
    "import cv2 \n",
    "import numpy as np \n",
    "import mediapipe as mp \n",
    "from keras.models import load_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collect():\n",
    "    def inFrame(lst):\n",
    "        if lst[28].visibility > 0.6 and lst[27].visibility > 0.6 and lst[15].visibility>0.6 and lst[16].visibility>0.6:\n",
    "            return True \n",
    "        return False\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    name = input(\"Enter the name of the Asana : \")\n",
    "\n",
    "    holistic = mp.solutions.pose\n",
    "    holis = holistic.Pose()\n",
    "    drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    X = []\n",
    "    data_size = 0\n",
    "\n",
    "    while True:\n",
    "        lst = []\n",
    "\n",
    "        _, frm = cap.read()\n",
    "\n",
    "        frm = cv2.flip(frm, 1)\n",
    "\n",
    "        res = holis.process(cv2.cvtColor(frm, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if res.pose_landmarks and inFrame(res.pose_landmarks.landmark):\n",
    "            for i in res.pose_landmarks.landmark:\n",
    "                lst.append(i.x - res.pose_landmarks.landmark[0].x)\n",
    "                lst.append(i.y - res.pose_landmarks.landmark[0].y)\n",
    "\n",
    "            X.append(lst)\n",
    "            data_size = data_size+1\n",
    "\n",
    "        else: \n",
    "            cv2.putText(frm, \"Make Sure Full body visible\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2)\n",
    "\n",
    "        drawing.draw_landmarks(frm, res.pose_landmarks, holistic.POSE_CONNECTIONS)\n",
    "\n",
    "        cv2.putText(frm, str(data_size), (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),2)\n",
    "\n",
    "        cv2.imshow(\"window\", frm)\n",
    "\n",
    "        if cv2.waitKey(1) == 27 or data_size>80:\n",
    "            cv2.destroyAllWindows()\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "\n",
    "    np.save(f\"{name}.npy\", np.array(X))\n",
    "    print(np.array(X).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
